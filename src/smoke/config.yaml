features:
  default:
    system_prompt_template: "You are a helpful assistant."
    user_prompt_template: "{text}"
  summarization:
    system_prompt_template: "You are a helpful text assistant dedicated to providing accurate, respectful, and thoughtful assistance. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity."
    user_prompt_template: '''Summarize the following text using precise and concise language. Use headers and bulleted lists in the summary. Maintain the meaning and factual accuracy. # Article:  {text}'''

vendors:
  openai:
    api_key_env: OPENAI_API_KEY
    api_base: null
    model_config:
      gpt-4:
        tokenizer_type: "tiktoken"
      gpt-3.5-turbo:
        tokenizer_type: "tiktoken"

  together-ai:
    api_key_env: TOGETHER_AI_API_KEY
    api_base: https://api.together.xyz/v1
    model_config:
      "moz/llama-3-1-8b-instruct-turbo":
        tokenizer_type: "huggingface"
        tokenizer: "meta-llama/Llama-3.1-8B-Instruct"
      "moz/llama-3-3-70b-instruct-turbo":
        tokenizer_type: "huggingface"
        tokenizer: "meta-llama/Llama-3.3-70B-Instruct"

  groq:
    api_key_env: GROQ_API_KEY
    api_base: "https://api.groq.com/openai/v1"
    model_config:
      "llama-3.1-8b-instant":
        tokenizer_type: "huggingface"
        tokenizer: "meta-llama/Llama-3.1-8B-Instruct"
      "llama-3.3-70b-versatile":
        tokenizer_type: "huggingface"
        tokenizer: "meta-llama/Llama-3.3-70B-Instruct"

  flower-ai:
    api_key_env: FLOWER_API_KEY
    api_base: "https://api.flower.ai/v1"
    model_config:
      "meta/llama3.1-8b/instruct-int4":
        tokenizer_type: "huggingface"
        tokenizer: "clowman/Llama-3.1-8B-Instruct-GPTQ-Int4"
      "meta/llama3.3-70b/instruct-int4'":
        tokenizer_type: "huggingface"
        tokenizer: "Satwik11/Llama-3.3-70B-Instruct-AutoRound-GPTQ-4bit"

  ollama:
    api_key_env: OLLAMA_API_KEY
    api_base: "http://localhost:11434/v1"
    model_config:
      "TheBloke/Mistral-7B-Instruct-v0.2-AWQ":
        uri: "http://localhost:8000/v1/chat/completions"
        temperature: 0.0
        max_tokens: 1000
        tokenizer_type: "huggingface"
        tokenizer: "mistralai/Mistral-7B-Instruct-v0.2"